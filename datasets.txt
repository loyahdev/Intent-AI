Large Datasets for Advanced Intent Classification of Content

To train an advanced intent classification model that flags manipulative, polarizing, emotionally charged, and otherwise impactful content, you can leverage several large, pre-labeled English-language datasets. Below we list high-quality datasets spanning news articles, social media, and political discourse, each labeled for one or more relevant dimensions (e.g. propaganda, bias, persuasion, sentiment, etc.). These datasets are all publicly available and can be merged into a unified CSV with fields like text, manipulative, informative, polarizing, emotionally_loaded, and additional specific labels. The combined size of these corpora well exceeds 20,000 examples, ensuring robust coverage of real-world content diversity.

News and Political Discourse Datasets (Manipulation, Bias, Propaganda)
	•	Fake-and-Real News Dataset (ISOT) – A popular Kaggle dataset of ~45,000 news articles split into “Fake” vs “True” classes, originally collected by the University of Victoria. It contains 23,502 fake news articles (from unreliable or manipulative sources) and 21,417 true news articles (from legitimate outlets) ￼. Each entry includes the article text (plus title, date, and subject metadata), making it straightforward to label deceptive/manipulative vs. informative content for training. Download: Provided on Kaggle as two CSV files (Fake.csv and True.csv) – one can combine these with a label column (e.g., manipulative=1 for fake, informative=1 for true) ￼.
	•	SemEval-2019 Hyperpartisan News – A large news bias dataset (~200k articles) released for SemEval Task 4 (Hyperpartisan News Detection). Articles are labeled as either hyperpartisan (extremely biased/political) or neutral/least-biased, based on their publisher’s known leanings ￼. The full corpus contains roughly 100,000 hyperpartisan articles vs. 100,000 non-partisan articles ￼, spanning a wide range of topics. This is ideal for detecting polarizing, one-sided content versus balanced journalism. Download: The dataset is available via Zenodo and includes training, validation, and test splits in XML format. After parsing out the text and label, it can be merged by adding a polarizing or bias binary field (1 for hyperpartisan). The size ensures ample (>20k) examples of biased vs. unbiased news.
	•	Propaganda Techniques Corpus (SemEval-2020 Task 11) – A fine-grained propaganda detection dataset of news articles annotated at multiple levels ￼. It includes 371 training articles and additional dev/test articles, with sentence-level labels (propagandistic vs not) and span-level annotations for 18 propaganda techniques (e.g. Loaded Language, Name Calling, Appeal to Fear) ￼ ￼. This corpus lets you capture manipulative rhetoric and emotionally loaded language in news. For integration, one can use the article-level label (propaganda vs non_propaganda) as a manipulative flag, and even create features for specific techniques (e.g. a text span with Loaded Language could set emotionally_loaded=1). Download: The data and annotations are published on Zenodo and the task website, provided as text files plus label files ￼.
	•	LUN Unreliable News Dataset (Rashkin et al. 2017) – A research dataset of 17,000+ news articles covering multiple manipulative content types ￼. It comprises articles labeled as Propaganda, Satire, or Hoax – all considered untrustworthy or manipulative genres – which were compared against real news in the study ￼. This dataset is useful to generalize detection of persuasion and deception tactics: propaganda articles in particular directly target bias and influence, while satire/hoaxes often use misleading or outrage-inducing content. You can assign manipulative=1 for these categories and combine with a set of true/informative news for contrast. Download: While not packaged on a single site, the data sources are described by Rashkin et al. (2017) ￼ and have been used in follow-up work; for example, the LUN corpus (17,250 articles from those categories) is referenced on PapersWithCode ￼. One can reconstruct it by scraping the outlets mentioned in the paper or by finding community shares of the dataset.

Social Media and Conversation Datasets (Persuasion, Emotion, Urgency)
	•	ChangeMyView Persuasion Corpus (Webis-CMV-20) – A large-scale dataset of Reddit discussions from r/ChangeMyView where users attempt to persuade the original poster. It includes all posts and comments from 2013–2017 (thousands of threads) and provides derived sub-datasets for persuasiveness prediction (i.e. which comments successfully changed the poster’s view) ￼. Successful persuasive comments are marked by a “delta” award. This corpus directly targets persuasion and argumentation signals in long-form social media content. You can label comments or arguments with a persuasion_success field (1 if the comment convinced someone, 0 otherwise) to train a model on detecting persuasive language. Download: The full dataset is available via the Webis group – e.g., on Zenodo – and in the ConvoKit toolkit as Winning Arguments Corpus. Each entry can be merged into your CSV with its text and a persuasive label.
	•	GoEmotions (Google’s Emotion Dataset) – A 58,000-example corpus of Reddit comments annotated with 27 emotion categories (plus Neutral) ￼. It is the largest human-labeled emotion dataset to date, covering fine-grained emotions like admiration, anger, fear, sadness, joy, disgust, etc. ￼. This dataset is perfect for capturing emotional tone and sentiment intensity in text. For your needs, you could map certain strong emotions to an emotionally_loaded flag (for example, if a comment is labeled with anger, fear, or other high-arousal emotions, mark it as emotionally loaded). It also provides a basis for a sentiment_intensity score by leveraging the range of labeled emotions. Download: GoEmotions is openly accessible – e.g. via the Hugging Face Datasets library or Google’s GitHub – in CSV format with a text and multi-label emotion columns. You can directly merge it by aligning its text and adding binary columns for each emotion or an overall emotional_intensity metric.
	•	HumAID Disaster Tweets (Urgency and Outrage in Crisis) – The HumAID Twitter dataset contains “several thousands” of tweets posted during 19 major natural disasters (2016–2019), each manually labeled into 11 humanitarian categories ￼ ￼. Notably, it has a category for “Requests or urgent needs”, which explicitly marks tweets that convey urgent appeals for help ￼. It also captures other emotionally charged or critical content (e.g. reports of injured/dead people, expressions of support, etc.). This dataset lets you train for urgency detection – you can set an urgency field based on whether a tweet’s label is urgent need or not. It also reflects moral outrage or distress indirectly through categories like casualties and pleas for help, aligning with high emotional intensity in crisis contexts. Download: The dataset is available from Qatar Computing Research Institute (QCRI) on their CrisisNLP platform and Harvard Dataverse ￼. Tweets are provided with their text and a label; after hydration (retrieving text via tweet IDs if needed), you can integrate them into your CSV (e.g., urgent=1 for tweets in the Requests or urgent needs class).

Each of these datasets brings a different slice of real-world content – from news articles rife with propaganda or bias, to social media comments with persuasive or emotional language, to crisis communications with urgent tones. By merging them on a common text field and aligning their label columns (e.g. manipulative, polarizing, bias, propaganda, persuasion, emotionally_loaded, urgency, etc.), you can create a comprehensive training dataset far larger than 20k examples. This combined resource will cover: manipulative vs. informative content, degrees of political bias and propaganda, sentiment and emotion intensity, persuasive argumentation, and even the presence of deceptive or urgent appeals – providing a rich foundation for an advanced intent classification model.

Sources: The datasets above are documented in official papers and repositories: e.g., the Fake/Real news counts are from the ISOT study ￼, hyperpartisan data from SemEval/PAN ￼, the propaganda corpus from SemEval-2020 Task 11 ￼, Rashkin’s unreliable news from EMNLP 2017 ￼ ￼, the ChangeMyView corpus from a Webis release ￼, GoEmotions from an ACL publication ￼, and HumAID from crisis informatics research ￼ ￼. Each link provides access or further references for downloading the data. Ensure to review the licensing and citation requirements for each dataset when using them.